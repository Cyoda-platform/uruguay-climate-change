# 🌍 Uruguay Climate Change Monitoring & AI Analysis System

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

> An intelligent climate monitoring platform that combines Machine Learning, Generative AI, and enterprise data management to analyze Uruguay's climate patterns and provide actionable insights for environmental sustainability.

## 🎯 Problem Statement

Climate change poses significant risks to Uruguay's agriculture, water resources, and ecosystems. However, raw climate data alone doesn't tell the full story. Decision-makers need:
- **Predictive insights** to anticipate extreme weather events
- **AI-powered analysis** to understand complex climate patterns
- **Real-time alerts** for anomalous conditions
- **Actionable recommendations** backed by intelligent analysis

## 💡 Our Solution

We built an end-to-end AI-powered climate monitoring system that:

1. **Analyzes Historical Data** - Processes 50+ climate indicators from World Bank datasets
2. **Predicts Future Trends** - Uses LSTM neural networks and Prophet models for forecasting
3. **Detects Anomalies** - Identifies unusual patterns using isolation forests and statistical methods
4. **Generates AI Insights** - Leverages Google Gemini AI for natural language analysis and recommendations
5. **Manages Alerts** - Integrates with Cyoda MCP (Model Context Protocol) for enterprise alert management
6. **Visualizes Results** - Provides an intuitive React-based dashboard

## 🏆 Unique Features

### 🤖 AI & ML Integration
- **Custom LSTM Networks** for temperature forecasting (30-day predictions)
- **Prophet Models** for seasonal decomposition and trend analysis
- **XGBoost & LightGBM** for climate pattern classification
- **Anomaly Detection** using Isolation Forest and statistical methods
- **Google Gemini 1.5 Flash** for context-aware climate insights

### 🔗 Cyoda MCP Integration (BONUS)
Our project uniquely integrates with **Cyoda's Model Context Protocol (MCP)** - an emerging standard for AI-to-enterprise system communication:
- **Structured Alert Storage** - Climate alerts stored as entities in Cyoda
- **Workflow Automation** - Triggers automated responses to critical conditions
- **Cross-System Integration** - Enables seamless data flow between AI models and enterprise systems
- **Scalable Architecture** - Built for production deployment with enterprise-grade reliability

## 🎥 Demo Video

Video covers:
- Live dashboard walkthrough
- Real-time AI analysis with Gemini
- ML model predictions in action
- Cyoda MCP alert creation
- End-to-end data flow

## 📊 Dataset

### Primary Data Source: World Bank Climate Data
We use the **Climate Change Knowledge Portal** dataset for Uruguay, containing:
- **50+ climate indicators** spanning 1960-2021
- **Agricultural metrics** (land use, crop yields)
- **Temperature & precipitation** patterns
- **Environmental indicators** (CO2 emissions, forest coverage)

**Dataset File**: `src/data/climate-change_ury.csv` (5,600+ rows)

### Data Processing Pipeline
1. **Quality Control** - Missing value imputation, outlier detection
2. **Feature Engineering** - Seasonal components, rolling statistics, lag features
3. **Normalization** - MinMax scaling for neural networks
4. **Time Series Preparation** - Windowing for LSTM, reformatting for Prophet

## 🏗️ Architecture

### System Overview

```
┌─────────────────────────────────────────────────────────────────┐
│                         FRONTEND (React)                        │
│  • Dashboard UI  • Charts (Recharts)  • AI Chat Interface      │
└─────────────────────────┬───────────────────────────────────────┘
                          │ REST API
┌─────────────────────────▼───────────────────────────────────────┐
│                      BACKEND (Flask)                            │
│  ┌──────────────┐  ┌──────────────┐  ┌────────────────────┐     │
│  │ Data API     │  │ ML API       │  │ Gemini AI API      │     │
│  │ /api/data    │  │ /api/ml      │  │ /api/ai            │     │
│  └──────────────┘  └──────────────┘  └────────────────────┘     │
│  ┌──────────────────────────────────────────────────────────┐   │
│  │           Gemini-Cyoda Integration API                   │   │
│  │           /api/gemini-cyoda/analyze                      │   │
│  └──────────────────────────────────────────────────────────┘   │
└─────────┬───────────────────┬─────────────────┬────────────── ──┘
          │                   │                 │
┌─────────▼──────┐   ┌────────▼──────┐   ┌─────▼──────────────┐
│   ML MODELS    │   │  GOOGLE       │   │   CYODA MCP        │
│                │   │  GEMINI AI    │   │                    │
│ • LSTM         │   │               │   │ • Entity Storage   │
│ • Prophet      │   │ • Analysis    │   │ • Alert Workflows  │
│ • XGBoost      │   │ • Insights    │   │ • Search API       │
│ • Isolation    │   │ • Recommendations  │ • Edge Messaging   │
│   Forest       │   │               │   │                    │
└────────────────┘   └───────────────┘   └────────────────────┘
```


## 🚀 Quick Start

### Prerequisites
- Python 3.9+
- Node.js 16+
- Docker & Docker Compose (optional)
- Google Gemini API key
- Cyoda MCP access (optional, for bonus features)

### Option 1: Docker Compose (Recommended)

```bash
# Clone repository
git clone <your-repo-url>
cd uruguay-climate-change

# Set up environment variables
cp .env.example .env
# Edit .env and add your GEMINI_API_KEY

# Build and run
docker-compose up -d 
#Alternatively: docker compose up -d

# Access the application
# Frontend: http://localhost:3000
# Backend: http://localhost:5000
```

### Option 2: Manual Setup

```bash
# 1. Backend setup
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# 2. Train ML models (takes 5-10 minutes)
python scripts/train_ml_models.py

# 3. Start backend
cd backend
export FLASK_APP=app.py
export GEMINI_API_KEY=your_key_here
flask run --host=0.0.0.0 --port=5000

# 4. Frontend setup (new terminal)
cd frontend
npm install
npm start

# Application runs at http://localhost:3000
```

See [SETUP.md](SETUP.md) for detailed installation instructions.

## 🔬 ML Model Training

### Training Pipeline

```bash
# Train all models at once
python scripts/train_ml_models.py

# Or train individually
python -m src.models.lstm_model
python -m src.models.prophet_model
python -m src.models.anomaly_detector
python -m src.models.climate_classifier
```

### Model Performance
- **LSTM Temperature Forecasting**: MAE < 1.2°C, RMSE < 1.8°C
- **Prophet Seasonal Analysis**: MAPE < 8%
- **Anomaly Detection**: 95%+ precision, 92%+ recall
- **Climate Classifier**: 89% accuracy on pattern recognition

See [ML_MODELS.md](ML_MODELS.md) for training details and evaluation metrics.

## 🎯 Key Features & Usage

### 1. Dashboard Overview
- Real-time climate metrics visualization
- Historical trends with interactive charts
- Key statistics cards (temperature, precipitation, emissions)

### 2. ML Predictions
- 30-day temperature forecasts
- Seasonal pattern analysis
- Anomaly detection alerts
- Climate pattern classification

### 3. AI-Powered Insights (Gemini)
- Natural language analysis of climate data
- Contextual recommendations
- Risk assessment
- Trend interpretation

### 4. Cyoda MCP Integration
- Automated alert creation
- Enterprise workflow integration
- Alert search and retrieval
- Cross-system notifications

### API Examples

```bash
# Get climate data
curl http://localhost:5000/api/data

# Get ML predictions
curl http://localhost:5000/api/ml/predict

# Get AI insights
curl -X POST http://localhost:5000/api/ai/analyze \
  -H "Content-Type: application/json" \
  -d '{"temperature": 0.1, "date": "2025-10-24"}'

# Create Cyoda alert (with Gemini analysis)
curl -X POST http://localhost:5000/api/gemini-cyoda/analyze \
  -H "Content-Type: application/json" \
  -d '{"temperature": 0.1, "location": "Uruguay", "date": "2025-10-24"}'
```

## 🛠️ Technology Stack

### Backend
- **Flask** - REST API framework
- **TensorFlow/Keras** - LSTM neural networks
- **Prophet** - Time series forecasting
- **Scikit-learn** - ML algorithms
- **XGBoost & LightGBM** - Gradient boosting
- **Google Generative AI SDK** - Gemini integration
- **Pandas & NumPy** - Data processing

### Frontend
- **React** - UI framework
- **Recharts** - Data visualization
- **Axios** - API communication
- **React Router** - Navigation

### Infrastructure
- **Docker** - Containerization
- **Docker Compose** - Multi-container orchestration
- **Nginx** - Frontend serving
- **Gunicorn** - Production WSGI server

### AI & Integration
- **Google Gemini 1.5 Flash** - Generative AI
- **Cyoda MCP** - Enterprise integration protocol

## 📁 Project Structure

```
uruguay-climate-change/
├── backend/                # Flask API server
│   ├── api/               # API routes
│   │   ├── routes.py     # Core data endpoints
│   │   ├── ml_routes.py  # ML prediction endpoints
│   │   ├── gemini_routes.py          # Gemini AI endpoints
│   │   ├── alert_routes.py           # Cyoda alert endpoints
│   │   └── gemini_cyoda_routes.py    # Integrated AI+MCP endpoints
│   ├── config/            # Configuration
│   └── app.py            # Main Flask app
├── frontend/              # React application
│   ├── src/
│   │   ├── components/   # React components
│   │   ├── pages/        # Page components
│   │   └── services/     # API services
│   └── public/           # Static assets
├── src/                   # Core Python modules
│   ├── data/             # Data loading & preprocessing
│   ├── features/         # Feature engineering
│   ├── models/           # ML model implementations
│   │   ├── lstm_model.py
│   │   ├── prophet_model.py
│   │   ├── anomaly_detector.py
│   │   └── climate_classifier.py
│   ├── services/         # Business logic
│   │   ├── gemini_service.py
│   │   └── alert_service.py
│   ├── visualization/    # Plotting utilities
│   └── utils/           # Helper functions
├── scripts/              # Utility scripts
│   ├── train_ml_models.py       # Model training script
│   ├── download_data.sh         # Data acquisition
│   └── verify_deployment.sh     # Health checks
├── kubernetes/           # K8s deployment configs
├── models/              # Trained model files
├── docs/               # Additional documentation
├── docker-compose.yml  # Docker orchestration
├── Dockerfile         # Backend container
├── requirements.txt   # Python dependencies
└── README.md         # This file
```

## 🧪 Testing

```bash
# Run unit tests
pytest tests/

# Run integration tests
pytest tests/integration/

# Test API endpoints
python scripts/test_frontend_backend_connection.sh

# Verify deployment
bash scripts/verify_deployment.sh
```

## 🌐 Deployment

### Production Deployment (Cyoda Cloud)
Live at: https://client-app-uruguay-climate-eb270b9abddf48108ee3a64e82fcebc3.eu.cyoda.net/

## 🤝 Ethics & Responsibility

This project adheres to responsible AI principles:

- **Transparency**: All model decisions are explainable and traceable
- **Data Privacy**: No personal data collection; uses public datasets only
- **Bias Mitigation**: Models trained on comprehensive historical data
- **Environmental Impact**: Optimized model architectures for energy efficiency
- **Accessibility**: Free and open-source for public benefit

See [ETHICS.md](ETHICS.md) for detailed AI ethics statement.

## 📜 License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## 🙏 Acknowledgments

- **World Bank** - Climate Change Knowledge Portal dataset
- **Google** - Gemini AI API access
- **Cyoda** - MCP integration platform
- **Open Source Community** - TensorFlow, scikit-learn, Prophet, React, and all dependencies

## 📞 Contact & Support

- **Project Repository**: https://github.com/Cyoda-platform/uruguay-climate-change
- **Live Demo**: https://client-app-uruguay-climate-eb270b9abddf48108ee3a64e82fcebc3.eu.cyoda.net/
- **Documentation**: See `docs/` directory
- **Issues**: https://github.com/Cyoda-platform/uruguay-climate-change/issues
- **Discussions**: https://discord.com/invite/95rdAyBZr2

---

Built with ❤️ for a sustainable future 🌱
